# Projet simplon

Ce projet implÃ©mente une solution d'analyse de donnÃ©es de ventes pour une PME, utilisant une architecture Ã  deux services Docker pour le traitement et le stockage des donnÃ©es.

## ğŸ— Architecture

Le projet utilise une architecture Ã  deux services avec un flux de donnÃ©es complet :

```mermaid
graph TD
    GS[Google Sheets] -->|DonnÃ©es Source| PS[Python Service]
    subgraph Docker Environment
        PS[Python Service] -->|1. Import| DB[(SQLite DB)]
        PS -->|2. Analyse| DB
        PS -->|3. RÃ©sultats| OUT[Output Console]
    end
    
    subgraph Data Flow
        CSV1[Ventes CSV] -.->|Import| PS
        CSV2[Produits CSV] -.->|Import| PS
        CSV3[Magasins CSV] -.->|Import| PS
    end
    
    subgraph Analyses
        DB -->|Chiffre Affaires| OUT
        DB -->|Stock Valeur| OUT
        DB -->|Performance Magasins| OUT
    end
```

Le systÃ¨me est composÃ© de :
- **Service Python** : Conteneur exÃ©cutant les scripts d'import et d'analyse
- **Service SQLite** : Base de donnÃ©es stockant et servant les donnÃ©es
- **Flux de DonnÃ©es** : Pipeline automatisÃ© depuis Google Sheets jusqu'aux analyses

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ main.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ analysis.db
â””â”€â”€ README.md
```

## ğŸ—ƒ Structure des donnÃ©es

Le modÃ¨le de donnÃ©es suit une structure relationnelle avec trois tables principales :

```mermaid
erDiagram
    MAGASINS ||--o{ VENTES : "rÃ©alise"
    PRODUITS ||--o{ VENTES : "concerne"
    
    MAGASINS {
        integer ID_Magasin PK
        string Ville
        integer Nombre_de_salaries
    }
    
    PRODUITS {
        string ID_Reference_produit PK
        string Nom
        decimal Prix
        integer Stock
    }
    
    VENTES {
        date Date PK
        string ID_Reference_produit PK,FK
        integer ID_Magasin PK,FK
        integer Quantite
    }
```

CaractÃ©ristiques principales :
- Table **VENTES** avec clÃ© primaire composite (Date, ID_Reference_produit, ID_Magasin)
- Relations one-to-many entre MAGASINS/PRODUITS et VENTES
- Gestion des stocks et prix dans PRODUITS
- DonnÃ©es gÃ©ographiques et RH dans MAGASINS

## ğŸš€ Installation

1. Construire et dÃ©marrer les services :
```bash
docker-compose up --build
```

2. Interagir avec le docker SQlite
```bash
docker exec -it sqlite_service sqlite3 /db/analysis.db
```

## ğŸ“Š FonctionnalitÃ©s

### Import des donnÃ©es
- Import automatique des liens google sheets
- Gestion des doublons
- Validation des donnÃ©es

### Analyses disponibles
1. **Analyses temporelles**
   - Ã‰volution des ventes quotidiennes
   - Tendances par pÃ©riode
   - Jours de forte/faible activitÃ©

2. **Analyses spatiales**
   - Performance par magasin
   - Distribution gÃ©ographique des ventes
   - CorrÃ©lation taille Ã©quipe/performance

3. **Analyses produits**
   - Top des produits vendus
   - Rotation des stocks
   - Chiffre d'affaires par produit

## ğŸ›  Technologies utilisÃ©es

- Python 3.11
- SQLite3
- Docker & Docker Compose
- Pandas pour le traitement des donnÃ©es

## ğŸ“ Utilisation

1. **Importer les donnÃ©es**
```bash
docker-compose exec scripts python import_data.py
```

2. **Lancer les analyses**
```bash
docker-compose exec scripts python analyze_data.py
```

## ğŸ” Monitoring et maintenance

- Les logs sont disponibles via Docker
- Les rÃ©sultats d'analyses sont stockÃ©s dans la table `analyses_resultats`
- Backups automatiques de la base de donnÃ©es
